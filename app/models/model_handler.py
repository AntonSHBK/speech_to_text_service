import asyncio

import torch

from app.models.transcriber import WhisperTranscriber


class ModelHandler:
    """
    –£–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–≥—Ä—É–∑–∫–æ–π –º–æ–¥–µ–ª–∏ –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏.
    –ü–æ–∑–≤–æ–ª—è–µ—Ç –ª–µ–≥–∫–æ –∑–∞–º–µ–Ω—è—Ç—å –∏–ª–∏ –æ–±–Ω–æ–≤–ª—è—Ç—å –º–æ–¥–µ–ª–∏ –≤ –±—É–¥—É—â–µ–º.
    """

    def __init__(self, model_name="openai/whisper-base", cache_dir=None, device=None, **kwargs):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –º–æ–¥–µ–ª–∏.

        Args:
            model_name (str): –ù–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ Hugging Face (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "openai/whisper-base").
            cache_dir (str, optional): –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –∫–µ—à–∞ –º–æ–¥–µ–ª–∏.
            device (str, optional): –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ –¥–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è ("cpu" –∏–ª–∏ "cuda").
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–æ–¥–µ–ª–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `language`, `temperature`).
        """
        self.model_name = model_name
        self.cache_dir = cache_dir
        self.device = device or ("cuda" if torch.cuda.is_available() else "cpu")
        self.model_kwargs = kwargs
        self.lock = asyncio.Lock()

        self.transcriber = WhisperTranscriber(
            model_name=self.model_name,
            cache_dir=self.cache_dir,
            device=self.device,
            **self.model_kwargs
        )

    async def transcribe(self, audio_path: str, language: str = "ru", task: str = "transcribe", **kwargs) -> str:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞.

        Args:
            audio_path (str): –ü—É—Ç—å –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª—É.
            language (str, optional): –Ø–∑—ã–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "ru").
            task (str, optional): –¢–∏–ø –∑–∞–¥–∞—á–∏ ("transcribe" ‚Äî –æ–±—ã—á–Ω–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è, "translate" ‚Äî –ø–µ—Ä–µ–≤–æ–¥ –≤ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π).
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è `transcribe_audio_file()`.

        Returns:
            str: –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç.
        """
        async with self.lock:  # –ì–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ–º, —á—Ç–æ `generate()` –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–Ω–∏–º –ø–æ—Ç–æ–∫–æ–º
            return self.transcriber.transcribe_audio_file(audio_path, language=language, task=task, **kwargs)

    def batch_transcribe(self, audio_files: list, output_dir: str, language: str = "ru", task: str = "transcribe", **kwargs):
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞—É–¥–∏–æ—Ñ–∞–π–ª–æ–≤.

        Args:
            audio_files (list): –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ –∞—É–¥–∏–æ—Ñ–∞–π–ª–∞–º.
            output_dir (str): –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤.
            language (str, optional): –Ø–∑—ã–∫ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "ru").
            task (str, optional): –¢–∏–ø –∑–∞–¥–∞—á–∏ ("transcribe" –∏–ª–∏ "translate").
            **kwargs: –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (`temperature`, `max_new_tokens` –∏ —Ç. –¥.).

        Returns:
            dict: –°–ª–æ–≤–∞—Ä—å —Å —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è–º–∏ {—Ñ–∞–π–ª: —Ç–µ–∫—Å—Ç}.
        """
        return self.transcriber.batch_transcribe(audio_files, output_dir, language=language, task=task, **kwargs)


model_handler = ModelHandler(
    model_name="openai/whisper-tiny",
    cache_dir="app/data/cache_dir"
)

# üî• **–ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è**
if __name__ == "__main__":
    import asyncio

    model_handler = ModelHandler(
        model_name="openai/whisper-tiny",
        cache_dir="app/data/cache_dir",
        device="cpu",
    )

    async def main():
        audio_file = "./app/data/input/test.wav"
        transcript = await model_handler.transcribe(audio_file, language="ru", task="transcribe")
        print("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è:", transcript)

    asyncio.run(main())
